{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#################################################\n",
    "## load the data as it is and capture basic stats\n",
    "#################################################\n",
    "#################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "#\n",
    "pd.set_option('max_columns', 500)\n",
    "pd.set_option('max_colwidth', -1)\n",
    "pd.set_option('max_rows', 500)\n",
    "#\n",
    "import logging\n",
    "## https://www.patricksoftwareblog.com/python-logging-tutorial/\n",
    "logging.basicConfig(level=logging.WARNING, filename='LOG_curationVer11.log',         \\\n",
    "    filemode='w', format='')\n",
    "#    filemode='w', format='%(asctime)s %(levelname)s:%(message)s')\n",
    "#\n",
    "logging.warning(f\"\\n    *************************************************************** \\n    *************************************************************** \\n    *************************************************************** \")\n",
    "logging.warning(f\"\\n    *************************************************************** \\n    *************************************************************** \\n    *************************************************************** \")\n",
    "logging.warning(f\"\\n    *************************************************************** \\n    *************************************************************** \\n    *************************************************************** \")\n",
    "logging.warning(f\" Data Curation and Modelling Processing.\")\n",
    "logging.warning(f\"\\n    *************************************************************** \\n    *************************************************************** \\n    *************************************************************** \")\n",
    "logging.warning(f\"\\n    *************************************************************** \\n    *************************************************************** \\n    *************************************************************** \")\n",
    "logging.warning(f\"\\n    *************************************************************** \\n    *************************************************************** \\n    ***************************************************************  \\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Rows read into dataframe = all the rows\n",
      "NOTE: All columns are read in with dtype as str, i.e. all columns are of object type\n",
      "NOTE: keep_default_na=False is used, so all data is loaded as it is without automatic replacement with null or Nan\n",
      "shape = (271145, 15)\n",
      "Data loaded from this file = /home/rohit/PyWDUbuntu/DM2DataCuration/Athlete_Events_ORIGINAL.csv\n",
      "\n",
      "Data Rows = 271145\tData Columns = 15\n",
      "\n",
      "Columns names are:\n",
      "['ID', 'Name', 'Sex', 'Age', 'Height', 'Weight', 'Team', 'NOC', 'Games', 'Year', 'Season', 'City', 'Sport', 'Event', 'Medal']\n",
      "\n",
      "\n",
      "Summary statistics for each column........\n",
      "\n",
      "**** For column #1\tcolumn name = ID:\n",
      "\n",
      "unique values = 135570\n",
      "count empty strings = 0\n",
      "count null values (this should be zero as keep_default_na=False is used) = 0\n",
      "count cells with value NA or na = 0\n",
      "count cells with value N/A or n/a = 0\n",
      "count     271145\n",
      "unique    135570\n",
      "top       77710 \n",
      "freq      58    \n",
      "Name: ID, dtype: object\n",
      "\n",
      "\n",
      "**** For column #2\tcolumn name = Name:\n",
      "\n",
      "unique values = 134684\n",
      "count empty strings = 2\n",
      "count null values (this should be zero as keep_default_na=False is used) = 0\n",
      "count cells with value NA or na = 0\n",
      "count cells with value N/A or n/a = 0\n",
      "count     271145              \n",
      "unique    134684              \n",
      "top       Robert Tait McKenzie\n",
      "freq      58                  \n",
      "Name: Name, dtype: object\n",
      "\n",
      "\n",
      "**** For column #3\tcolumn name = Sex:\n",
      "\n",
      "unique values = 7\n",
      "count empty strings = 2711\n",
      "count null values (this should be zero as keep_default_na=False is used) = 0\n",
      "count cells with value NA or na = 0\n",
      "count cells with value N/A or n/a = 0\n",
      "count     271145\n",
      "unique    7     \n",
      "top       M     \n",
      "freq      187110\n",
      "Name: Sex, dtype: object\n",
      "\n",
      "\n",
      "**** For column #4\tcolumn name = Age:\n",
      "\n",
      "unique values = 96\n",
      "count empty strings = 2706\n",
      "count null values (this should be zero as keep_default_na=False is used) = 0\n",
      "count cells with value NA or na = 9440\n",
      "count cells with value N/A or n/a = 0\n",
      "count     271145\n",
      "unique    96    \n",
      "top       23    \n",
      "freq      21677 \n",
      "Name: Age, dtype: object\n",
      "\n",
      "\n",
      "**** For column #5\tcolumn name = Height:\n",
      "\n",
      "unique values = 139\n",
      "count empty strings = 2706\n",
      "count null values (this should be zero as keep_default_na=False is used) = 0\n",
      "count cells with value NA or na = 59386\n",
      "count cells with value N/A or n/a = 0\n",
      "count     271145\n",
      "unique    139   \n",
      "top       NA    \n",
      "freq      59386 \n",
      "Name: Height, dtype: object\n",
      "\n",
      "\n",
      "**** For column #6\tcolumn name = Weight:\n",
      "\n",
      "unique values = 220\n",
      "count empty strings = 2706\n",
      "count null values (this should be zero as keep_default_na=False is used) = 0\n",
      "count cells with value NA or na = 61999\n",
      "count cells with value N/A or n/a = 0\n",
      "count     271145\n",
      "unique    220   \n",
      "top       NA    \n",
      "freq      61999 \n",
      "Name: Weight, dtype: object\n",
      "\n",
      "\n",
      "**** For column #7\tcolumn name = Team:\n",
      "\n",
      "unique values = 1178\n",
      "count empty strings = 2709\n",
      "count null values (this should be zero as keep_default_na=False is used) = 0\n",
      "count cells with value NA or na = 0\n",
      "count cells with value N/A or n/a = 0\n",
      "count     271145       \n",
      "unique    1178         \n",
      "top       United States\n",
      "freq      16615        \n",
      "Name: Team, dtype: object\n",
      "\n",
      "\n",
      "**** For column #8\tcolumn name = NOC:\n",
      "\n",
      "unique values = 231\n",
      "count empty strings = 2842\n",
      "count null values (this should be zero as keep_default_na=False is used) = 0\n",
      "count cells with value NA or na = 0\n",
      "count cells with value N/A or n/a = 0\n",
      "count     271145\n",
      "unique    231   \n",
      "top       USA   \n",
      "freq      17456 \n",
      "Name: NOC, dtype: object\n",
      "\n",
      "\n",
      "**** For column #9\tcolumn name = Games:\n",
      "\n",
      "unique values = 52\n",
      "count empty strings = 2837\n",
      "count null values (this should be zero as keep_default_na=False is used) = 0\n",
      "count cells with value NA or na = 0\n",
      "count cells with value N/A or n/a = 0\n",
      "count     271145     \n",
      "unique    52         \n",
      "top       2000 Summer\n",
      "freq      13751      \n",
      "Name: Games, dtype: object\n",
      "\n",
      "\n",
      "**** For column #10\tcolumn name = Year:\n",
      "\n",
      "unique values = 36\n",
      "count empty strings = 2839\n",
      "count null values (this should be zero as keep_default_na=False is used) = 0\n",
      "count cells with value NA or na = 0\n",
      "count cells with value N/A or n/a = 0\n",
      "count     271145\n",
      "unique    36    \n",
      "top       1992  \n",
      "freq      16261 \n",
      "Name: Year, dtype: object\n",
      "\n",
      "\n",
      "**** For column #11\tcolumn name = Season:\n",
      "\n",
      "unique values = 3\n",
      "count empty strings = 2838\n",
      "count null values (this should be zero as keep_default_na=False is used) = 0\n",
      "count cells with value NA or na = 0\n",
      "count cells with value N/A or n/a = 0\n",
      "count     271145\n",
      "unique    3     \n",
      "top       Summer\n",
      "freq      219969\n",
      "Name: Season, dtype: object\n",
      "\n",
      "\n",
      "**** For column #12\tcolumn name = City:\n",
      "\n",
      "unique values = 43\n",
      "count empty strings = 2837\n",
      "count null values (this should be zero as keep_default_na=False is used) = 0\n",
      "count cells with value NA or na = 0\n",
      "count cells with value N/A or n/a = 0\n",
      "count     271145\n",
      "unique    43    \n",
      "top       London\n",
      "freq      22231 \n",
      "Name: City, dtype: object\n",
      "\n",
      "\n",
      "**** For column #13\tcolumn name = Sport:\n",
      "\n",
      "unique values = 67\n",
      "count empty strings = 2840\n",
      "count null values (this should be zero as keep_default_na=False is used) = 0\n",
      "count cells with value NA or na = 0\n",
      "count cells with value N/A or n/a = 0\n",
      "count     271145   \n",
      "unique    67       \n",
      "top       Athletics\n",
      "freq      38105    \n",
      "Name: Sport, dtype: object\n",
      "\n",
      "\n",
      "**** For column #14\tcolumn name = Event:\n",
      "\n",
      "unique values = 599\n",
      "count empty strings = 2837\n",
      "count null values (this should be zero as keep_default_na=False is used) = 0\n",
      "count cells with value NA or na = 0\n",
      "count cells with value N/A or n/a = 0\n",
      "count     271145                 \n",
      "unique    599                    \n",
      "top       Football Men's Football\n",
      "freq      5719                   \n",
      "Name: Event, dtype: object\n",
      "\n",
      "\n",
      "**** For column #15\tcolumn name = Medal:\n",
      "\n",
      "unique values = 8\n",
      "count empty strings = 67320\n",
      "count null values (this should be zero as keep_default_na=False is used) = 0\n",
      "count cells with value NA or na = 173902\n",
      "count cells with value N/A or n/a = 0\n",
      "count     271145\n",
      "unique    8     \n",
      "top       NA    \n",
      "freq      173902\n",
      "Name: Medal, dtype: object\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inFilePath = '/home/rohit/PyWDUbuntu/DM2DataCuration/'\n",
    "inDataFile = 'Athlete_Events_ORIGINAL.csv'\n",
    "#\n",
    "## -1 means read all rows\n",
    "rowsToRead = -1\n",
    "#rowsToRead = 5\n",
    "## load all columns into dataframe as string (object) by specifying the\n",
    "##      dtype=str during loading, all the columns dtpye is object\n",
    "#\n",
    "if rowsToRead == -1:\n",
    "    dfin = pd.read_csv(inFilePath+inDataFile, sep=',', dtype=str, header=0, \\\n",
    "                       keep_default_na=False, low_memory=False )\n",
    "else:\n",
    "    dfin = pd.read_csv(inFilePath+inDataFile, sep=',', dtype=str, header=0, \\\n",
    "                       nrows=rowsToRead, keep_default_na=False, low_memory=False )\n",
    "#\n",
    "logging.warning(f\"\\n\\n    *************************** \\n    *************************** \")\n",
    "logging.warning(f\"\\n    *************************** \\n    *************************** \\n\\n\")\n",
    "print(f'# Rows read into dataframe = {rowsToRead if rowsToRead != -1 else \"all the rows\"}')\n",
    "logging.warning(f'# Rows read into dataframe = {rowsToRead if rowsToRead != -1 else \"all the rows\"}')\n",
    "#\n",
    "print(f'NOTE: All columns are read in with dtype as str, i.e. all columns are of object type')\n",
    "logging.warning(f'NOTE: All columns are read in with dtype as str, i.e. all columns are of object type')\n",
    "print(f'NOTE: keep_default_na=False is used, so all data is loaded as it is without automatic replacement with null or Nan')\n",
    "logging.warning(f'NOTE: keep_default_na=False is used, so all data is loaded as it is without automatic replacement with null or Nan')\n",
    "#\n",
    "#\n",
    "#\n",
    "print(f\"shape = {dfin.shape}\")\n",
    "#\n",
    "print(f\"Data loaded from this file = {inFilePath+inDataFile}\\n\")\n",
    "logging.warning(f\"Data loaded from this file = {inFilePath+inDataFile}\\n\")\n",
    "#\n",
    "print(f\"Data Rows = {dfin.shape[0]}\\tData Columns = {dfin.shape[1]}\\n\")\n",
    "logging.warning(f\"Data Rows = {dfin.shape[0]}\\tData Columns = {dfin.shape[1]}\\n\")\n",
    "#\n",
    "print(f\"Columns names are:\\n{[colName for colName in list(dfin)]}\")\n",
    "logging.warning(f\"Columns names are:\\n{[colName for colName in list(dfin)]}\")\n",
    "logging.warning(f\"\\n\")\n",
    "#\n",
    "#\n",
    "#\n",
    "## capture columnwise information into logfile\n",
    "colNameList = list(dfin)\n",
    "logging.warning(f\"\\n\\n    *************************** \\n    *************************** \")\n",
    "logging.warning(f\"\\n    *************************** \\n    *************************** \\n\\n\")\n",
    "print(f\"\\n\\nSummary statistics for each column........\\n\")\n",
    "logging.warning(f\"\\n\\nSummary statistics for each column........\\n\")\n",
    "for colIdx, colName in enumerate(colNameList):\n",
    "    #print(f\"{i}\")\n",
    "    print(f\"**** For column #{colIdx+1}\\tcolumn name = {colName}:\\n\")\n",
    "    print(f\"unique values = {dfin[colNameList[colIdx]].nunique()}\")\n",
    "    print(f\"count empty strings = {(dfin[colNameList[colIdx]] == '').sum()}\")\n",
    "    print(f\"count null values (this should be zero as keep_default_na=False is used) = {dfin[colNameList[colIdx]].isnull().sum(axis = 0)}\")\n",
    "    print(f\"count cells with value NA or na = {(dfin[colNameList[colIdx]].str.lower() == r'na').sum()}\")\n",
    "    print(f\"count cells with value N/A or n/a = {(dfin[colNameList[colIdx]].str.lower() == r'n/a').sum()}\")\n",
    "    print(f\"{dfin[colNameList[colIdx]].describe()}\")\n",
    "    print(f\"\\n\")\n",
    "    #\n",
    "    logging.warning(f\"**** For column #{colIdx+1}\\tcolumn name = {colName}:\\n\")\n",
    "    logging.warning(f\"unique values = {dfin[colNameList[colIdx]].nunique()}\")\n",
    "    logging.warning(f\"count empty strings = {(dfin[colNameList[colIdx]] == '').sum()}\")\n",
    "    logging.warning(f\"count null values (this should be zero as keep_default_na=False is used) = {dfin[colNameList[colIdx]].isnull().sum(axis = 0)}\")\n",
    "    logging.warning(f\"count cells with value NA or na = {(dfin[colNameList[colIdx]].str.lower() == r'na').sum()}\")\n",
    "    logging.warning(f\"count cells with value N/A or n/a = {(dfin[colNameList[colIdx]].str.lower() == r'n/a').sum()}\")\n",
    "    logging.warning(f\"{dfin[colNameList[colIdx]].describe()}\")\n",
    "    logging.warning(f\"\\n\")\n",
    "#\n",
    "del colNameList, colIdx, colName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################\n",
    "#################################################\n",
    "## cleaning starts\n",
    "#################################################\n",
    "#################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Rows read into dataframe = all the rows\n",
      "\n",
      "All rows read into dataframe as str (object) dtype.\n",
      "\n",
      "Number of rows at this time = 271145\n",
      "\n",
      "ACTION:\n",
      "Added new column for serial number as MySN with values from 1 to number of data rows.\n",
      "Converted MySN column to str as well.\n",
      "\n",
      "ACTION:\n",
      "Strip function applied to all cells.\n",
      "\n",
      "ACTION:\n",
      "Lowercase function applied all cells.\n",
      "\n",
      "ACTION:\n",
      "Any blank cells replaced with word MISSING.\n",
      "Any cells with value as na replaced with word MISSING.\n",
      "\n",
      "ACTION:\n",
      "Delete duplicates, considering all coumns except MySN.\n",
      "\n",
      "Number of rows before deduplication = 271145\n",
      "\n",
      "No. of rows deleted as duplicates = 13980\n",
      "\n",
      "\n",
      "Number of rows after deduplication = 257165\n",
      "\n",
      "ACTION:\n",
      "Considering all coumns except MySN, ID and Name, remove rows with all remaining columns = MISSING.\n",
      "\n",
      "No. of rows deleted = 1255\n",
      "\n",
      "Number of rows at this time = 255910\n",
      "\n",
      "ACTION:\n",
      "For these columns: NOC, Games, Year, Season, City, Sport, Event, Medal....\n",
      "Removing rows where ALL these values are = MISSING.\n",
      "\n",
      "No. of rows deleted = 128\n",
      "\n",
      "Number of rows at this time = 255782\n",
      "\n",
      "ACTION:\n",
      "Clean up of Name column.\n",
      "For each ID, found Name corresponding to maximum count. Then for each ID, replaced all the Name with that maximum count Name.\n",
      "\n",
      "ACTION:\n",
      "Clean up of Sex column.\n",
      "\n",
      "Unique values before cleanup=\n",
      "['m', 'male', 'f', 'MISSING', 'female']\n",
      "\n",
      "Unique values after cleanup=\n",
      "['m', 'f', 'MISSING']\n",
      "\n",
      "Additional clean up -- using cross referencing to fill missing values.\n",
      "\n",
      "Missing values count before cleanup=\n",
      "5\n",
      "\n",
      "Missing values count after cleanup=\n",
      "0\n",
      "\n",
      "ACTION:\n",
      "Clean up of Age column.\n",
      "Replaced any values which were not numeric with the word MISSING.\n",
      "\n",
      "ACTION:\n",
      "Clean up of Height column.\n",
      "Floored decimal values to integer values.\n",
      "Replaced values above 250 with the word MISSING.\n",
      "count of rows with Height above threshold that are marked as MISSING = 0\n",
      "\n",
      "ACTION:\n",
      "Clean up of Weight column.\n",
      "Replaced six invalid values with valid values: MySN of 40990-92, 246671-73.\n",
      "Floored decimal values to integer values.\n",
      "\n",
      "ACTION:\n",
      "Clean up of Team column.\n",
      "\n",
      "Using cross referencing to fill missing values.\n",
      "\n",
      "Missing values count before cleanup=\n",
      "3\n",
      "\n",
      "Missing values count after cleanup=\n",
      "0\n",
      "\n",
      "ACTION:\n",
      "Clean up of NOC column.\n",
      "\n",
      "Using cross referencing to fill missing values.\n",
      "\n",
      "Missing values count before cleanup=\n",
      "5\n",
      "\n",
      "Missing values count after cleanup=\n",
      "0\n",
      "\n",
      "ACTION:\n",
      "Clean up of Games column.\n",
      "Note: No clean up required\n",
      "\n",
      "ACTION:\n",
      "Clean up of Year column.\n",
      "\n",
      "Year does not always match the data as per the Games column. So overwriting all values by extracting from Games column.\n",
      "\n",
      "Count of rows with mismatch for YEAR = 224\n",
      "\n",
      "ACTION:\n",
      "Clean up of Season column.\n",
      "\n",
      "Season does not always match the data as per the Games column. So overwriting all values by extracting from Games column.\n",
      "\n",
      "Count of rows with mismatch for SEASON = 176\n",
      "\n",
      "ACTION:\n",
      "Clean up of City column.\n",
      "Note: No clean up required\n",
      "\n",
      "ACTION:\n",
      "Clean up of Sport column.\n",
      "\n",
      "The Event name starts with the text of the Sport usually.\n",
      "When it does not, the value is assumed to be wrong and needs to be corrected.\n",
      "\n",
      "Using cross referencing to fill missing values and correct wrong values.\n",
      "\n",
      "Missing values count before cleanup=\n",
      "3\n",
      "\n",
      "Mismatch with Event name count before cleanup=\n",
      "3\n",
      "\n",
      "Missing values count after cleanup=\n",
      "0\n",
      "\n",
      "Mismatch with Event name count after cleanup=\n",
      "0\n",
      "\n",
      "ACTION:\n",
      "Clean up of Event column.\n",
      "Note: No clean up required\n",
      "\n",
      "ACTION:\n",
      "Clean up of Medal column.\n",
      "Any cell without medal replaced with 'no'.\n",
      "\n",
      "Unique values before cleanup=\n",
      "['MISSING', 'gold', 'bronze', 'silver', '3rd', '2nd', '1st']\n",
      "\n",
      "Unique values after cleanup=\n",
      "['no', 'gold', 'bronze', 'silver']\n",
      "\n",
      "ACTION:\n",
      "Delete duplicates, considering all coumns except MySN.\n",
      "\n",
      "Number of rows before deduplication = 255782\n",
      "\n",
      "No. of rows deleted as duplicates = 90\n",
      "\n",
      "\n",
      "Number of rows after deduplication = 255692\n",
      "\n",
      "Clean up of Dataframe completed.\n"
     ]
    }
   ],
   "source": [
    "dfin2clean = dfin.copy()\n",
    "del(dfin)\n",
    "#\n",
    "logging.warning(f\"\\n\\n    *************************** \\n    *************************** \")\n",
    "logging.warning(f\"\\n    *************************** \\n    *************************** \\n\\n\")\n",
    "print(f'# Rows read into dataframe = {rowsToRead if rowsToRead != -1 else \"all the rows\"}')\n",
    "logging.warning(f'# Rows read into dataframe = {rowsToRead if rowsToRead != -1 else \"all the rows\"}')\n",
    "#\n",
    "print(f\"\\nAll rows read into dataframe as str (object) dtype.\")\n",
    "logging.warning(f\"\\nAll rows read into dataframe as str (object) dtype.\")\n",
    "#\n",
    "print(f\"\\nNumber of rows at this time = {len(dfin2clean)}\")\n",
    "logging.warning(f\"\\nNumber of rows at this time = {len(dfin2clean)}\")\n",
    "#\n",
    "#\n",
    "#\n",
    "## ################\n",
    "## add Serial Number at the first position  -- called it MySN       ################\n",
    "#\n",
    "logging.warning(f\"\\n\\n    *************************** \\n    *************************** \")\n",
    "logging.warning(f\"\\n    *************************** \\n    *************************** \\n\\n\")\n",
    "# \n",
    "dfin2clean.insert(0, \"MySN\", range(1, len(dfin2clean)+1), True) # True means allow duplicates\n",
    "dfin2clean['MySN'] = dfin2clean['MySN'].astype('str')\n",
    "dfin2clean.dtypes\n",
    "#\n",
    "print(f\"\\nACTION:\\nAdded new column for serial number as MySN with values from 1 to number of data rows.\\\n",
    "\\nConverted MySN column to str as well.\")\n",
    "logging.warning(f\"\\nACTION:\\nAdded new column for serial number as MySN with values from 1 to number of data rows.\\\n",
    "\\nConverted MySN column to str as well.\")\n",
    "#\n",
    "#\n",
    "#\n",
    "## ################\n",
    "## strip all columns (trim of openrefine)       ################\n",
    "#\n",
    "logging.warning(f\"\\n\\n    *************************** \\n    *************************** \")\n",
    "logging.warning(f\"\\n    *************************** \\n    *************************** \\n\\n\")\n",
    "#             \n",
    "dfin2clean = dfin2clean.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "#\n",
    "print(f\"\\nACTION:\\nStrip function applied to all cells.\")\n",
    "logging.warning(f\"\\nACTION:\\nStrip function applied to all cells.\")\n",
    "#\n",
    "#\n",
    "#\n",
    "## ################\n",
    "## convert all the data to lowercase       ################\n",
    "#\n",
    "logging.warning(f\"\\n\\n    *************************** \\n    *************************** \")\n",
    "logging.warning(f\"\\n    *************************** \\n    *************************** \\n\\n\")\n",
    "#\n",
    "dfin2clean = dfin2clean.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "#\n",
    "print(f\"\\nACTION:\\nLowercase function applied all cells.\")\n",
    "logging.warning(f\"\\nACTION:\\nLowercase function applied all cells.\")\n",
    "#\n",
    "#\n",
    "#\n",
    "## ################\n",
    "## replace any blank cells with the word MISSING       ################\n",
    "## replace any cells with value na or n/a with the word MISSING\n",
    "#\n",
    "logging.warning(f\"\\n\\n    *************************** \\n    *************************** \")\n",
    "logging.warning(f\"\\n    *************************** \\n    *************************** \\n\\n\")\n",
    "#\n",
    "dfin2clean = dfin2clean.applymap(lambda x: 'MISSING' if x=='' else x)\n",
    "dfin2clean = dfin2clean.applymap(lambda x: 'MISSING' if x=='na' else x)\n",
    "dfin2clean = dfin2clean.applymap(lambda x: 'MISSING' if x==r'n/a' else x)\n",
    "#\n",
    "print(f\"\\nACTION:\\nAny blank cells replaced with word MISSING.\\nAny cells with value as na replaced with word MISSING.\")\n",
    "logging.warning(f\"\\nACTION:\\nAny blank cells replaced with word MISSING.\\nAny cells with value as na replaced with word MISSING.\")\n",
    "#\n",
    "#\n",
    "#\n",
    "## ################\n",
    "## delete row duplicates: Excluding MySN, the entire row delete if its a duplicate       ################\n",
    "#\n",
    "logging.warning(f\"\\n\\n    *************************** \\n    *************************** \")\n",
    "logging.warning(f\"\\n    *************************** \\n    *************************** \\n\\n\")\n",
    "#\n",
    "dfTemp = dfin2clean.copy()\n",
    "#\n",
    "print(f\"\\nACTION:\\nDelete duplicates, considering all coumns except MySN.\")\n",
    "(f\"\\nACTION:\\nDelete duplicates, considering all coumns except MySN.\")\n",
    "#\n",
    "print(f\"\\nNumber of rows before deduplication = {len(dfTemp)}\")\n",
    "logging.warning(f\"\\nNumber of rows before deduplication = {len(dfTemp)}\")\n",
    "#\n",
    "# create list of all columns except for MySN\n",
    "subsetCols = [col for col in list(dfTemp) if col not in ['MySN']]\n",
    "dfTemp.drop_duplicates(subset= subsetCols, keep='first', inplace=True)\n",
    "#\n",
    "print(f\"\\nNo. of rows deleted as duplicates = {dfin2clean.shape[0] -  dfTemp.shape[0]}\\n\")\n",
    "logging.warning(f\"\\nNo. of rows deleted as duplicates = {dfin2clean.shape[0] -  dfTemp.shape[0]}\\n\")\n",
    "#\n",
    "print(f\"\\nNumber of rows after deduplication = {len(dfTemp)}\")\n",
    "logging.warning(f\"\\nNumber of rows after deduplication = {len(dfTemp)}\")\n",
    "#\n",
    "## store all the MySN values for the deleted rows into the log file\n",
    "#\n",
    "setOrigSN = dfin2clean['MySN'].astype('int').copy()\n",
    "setOrigSN = set(setOrigSN.unique())\n",
    "setNoDuplicatesSN = dfTemp['MySN'].astype('int').copy()\n",
    "setNoDuplicatesSN = set(setNoDuplicatesSN.unique())\n",
    "#\n",
    "setDeletedMySNs = setOrigSN - setNoDuplicatesSN\n",
    "#\n",
    "setDeletedMySNs_asList = list(setDeletedMySNs)\n",
    "setDeletedMySNs_asList.sort()\n",
    "logging.warning(f\"\\n******* The rows with following MySN values were deleted as duplicates. *******\\n\")\n",
    "for val in setDeletedMySNs_asList:\n",
    "    logging.warning(f\"{val}\")\n",
    "logging.warning(f\"\\n******* End of deleted as duplicates information. *******\\n\")\n",
    "#\n",
    "dfin2clean = dfTemp.copy()\n",
    "#\n",
    "del dfTemp, subsetCols, setOrigSN, setNoDuplicatesSN, setDeletedMySNs_asList\n",
    "#\n",
    "#\n",
    "#\n",
    "## ################\n",
    "## delete all rows which have MISSING values for all the columns except, MySN, ID, Name       ################\n",
    "#\n",
    "logging.warning(f\"\\n\\n    *************************** \\n    *************************** \")\n",
    "logging.warning(f\"\\n    *************************** \\n    *************************** \\n\\n\")\n",
    "#\n",
    "dfTemp = dfin2clean.copy()\n",
    "#\n",
    "dfTemp = dfTemp[(dfTemp['Sex']    != 'MISSING') | (dfTemp['Age']    != 'MISSING') | \\\n",
    "                (dfTemp['Height'] != 'MISSING') | (dfTemp['Weight'] != 'MISSING') | \\\n",
    "                (dfTemp['Team']   != 'MISSING') | (dfTemp['NOC']    != 'MISSING') | \\\n",
    "                (dfTemp['Games']  != 'MISSING') | (dfTemp['Year']   != 'MISSING') | \\\n",
    "                (dfTemp['Season'] != 'MISSING') | (dfTemp['City']   != 'MISSING') | \\\n",
    "                (dfTemp['Sport']  != 'MISSING') | (dfTemp['Event']  != 'MISSING') | \\\n",
    "                (dfTemp['Medal']  != 'MISSING') ]\n",
    "#\n",
    "print(f\"\\nACTION:\\nConsidering all coumns except MySN, ID and Name, remove rows with all remaining columns = MISSING.\")\n",
    "logging.warning(f\"\\nACTION:\\nConsidering all coumns except MySN, ID and Name, remove rows with all remaining columns = MISSING.\")\n",
    "#\n",
    "print(f\"\\nNo. of rows deleted = {dfin2clean.shape[0] -  dfTemp.shape[0]}\")\n",
    "logging.warning(f\"\\nNo. of rows deleted = {dfin2clean.shape[0] -  dfTemp.shape[0]}\")\n",
    "#\n",
    "#\n",
    "print(f\"\\nNumber of rows at this time = {len(dfTemp)}\")\n",
    "logging.warning(f\"\\nNumber of rows at this time = {len(dfTemp)}\")\n",
    "#\n",
    "## store all the MySN values for the deleted rows into the log file\n",
    "#\n",
    "setOrigSN = dfin2clean['MySN'].astype('int').copy()\n",
    "setNoDuplicatesSN = dfTemp['MySN'].astype('int').copy()\n",
    "#\n",
    "setOrigSN = set(setOrigSN.unique())\n",
    "setNoDuplicatesSN = set(setNoDuplicatesSN.unique())\n",
    "#\n",
    "setDeletedMySNs = setOrigSN - setNoDuplicatesSN\n",
    "#\n",
    "setDeletedMySNs_asList = list(setDeletedMySNs)\n",
    "setDeletedMySNs_asList.sort()\n",
    "logging.warning(f\"\\n******* The rows with following MySN values were deleted. *******\\n\")\n",
    "for val in setDeletedMySNs_asList:\n",
    "    logging.warning(f\"{val}\")\n",
    "logging.warning(f\"\\n******* End of deleted as duplicates information. *******\\n\")\n",
    "#\n",
    "dfin2clean = dfTemp.copy()\n",
    "#\n",
    "del dfTemp, setOrigSN, setNoDuplicatesSN, setDeletedMySNs_asList\n",
    "#\n",
    "#\n",
    "#\n",
    "## ################\n",
    "## delete all rows which have MISSING values for all these columns:       ################\n",
    "##        NOC, Games, Year, Season, City, Sport, Event, Medal\n",
    "#\n",
    "logging.warning(f\"\\n\\n    *************************** \\n    *************************** \")\n",
    "logging.warning(f\"\\n    *************************** \\n    *************************** \\n\\n\")\n",
    "#\n",
    "print(f\"\\nACTION:\\nFor these columns: NOC, Games, Year, Season, City, Sport, Event, Medal....\")\n",
    "print(f\"Removing rows where ALL these values are = MISSING.\")\n",
    "logging.warning(f\"\\nACTION:\\nFor these columns: NOC, Games, Year, Season, City, Sport, Event, Medal....\")\n",
    "logging.warning(f\"Removing rows where ALL these values are = MISSING.\")\n",
    "#\n",
    "dfTemp = dfin2clean.copy()\n",
    "#\n",
    "dfTempDeletedRows = dfTemp[(dfTemp['NOC']    == 'MISSING')                        & \\\n",
    "                (dfTemp['Games']  == 'MISSING') & (dfTemp['Year']   == 'MISSING') & \\\n",
    "                (dfTemp['Season'] == 'MISSING') & (dfTemp['City']   == 'MISSING') & \\\n",
    "                (dfTemp['Sport']  == 'MISSING') & (dfTemp['Event']  == 'MISSING') & \\\n",
    "                (dfTemp['Medal']  == 'MISSING') ]\n",
    "#\n",
    "dfTemp = dfin2clean.copy()\n",
    "#\n",
    "dfTemp =            dfTemp[(dfTemp['NOC']    != 'MISSING')                        | \\\n",
    "                (dfTemp['Games']  != 'MISSING') | (dfTemp['Year']   != 'MISSING') | \\\n",
    "                (dfTemp['Season'] != 'MISSING') | (dfTemp['City']   != 'MISSING') | \\\n",
    "                (dfTemp['Sport']  != 'MISSING') | (dfTemp['Event']  != 'MISSING') | \\\n",
    "                (dfTemp['Medal']  != 'MISSING') ]\n",
    "#\n",
    "print(f\"\\nNo. of rows deleted = {len(dfTempDeletedRows)}\")\n",
    "logging.warning(f\"\\nNo. of rows deleted = {len(dfTempDeletedRows)}\")\n",
    "#\n",
    "#\n",
    "print(f\"\\nNumber of rows at this time = {len(dfTemp)}\")\n",
    "logging.warning(f\"\\nNumber of rows at this time = {len(dfTemp)}\")\n",
    "#\n",
    "## store all the MySN values for the deleted rows into the log file\n",
    "#\n",
    "setDeletedMySNs = dfTempDeletedRows['MySN'].astype('int').copy()\n",
    "setDeletedMySNs = set(setDeletedMySNs.unique())\n",
    "setDeletedMySNs_asList = list(setDeletedMySNs)\n",
    "setDeletedMySNs_asList.sort()\n",
    "#\n",
    "logging.warning(f\"\\n******* The rows with following MySN values were deleted. *******\\n\")\n",
    "for val in setDeletedMySNs_asList:\n",
    "    logging.warning(f\"{val}\")\n",
    "logging.warning(f\"\\n******* End of deleted rows information. *******\\n\")\n",
    "#\n",
    "dfin2clean = dfTemp.copy()\n",
    "#\n",
    "del dfTemp, dfTempDeletedRows, setDeletedMySNs_asList\n",
    "#\n",
    "#\n",
    "#\n",
    "## ################\n",
    "## cleanup of the Name column       ################\n",
    "#\n",
    "logging.warning(f\"\\n\\n    *************************** \\n    *************************** \")\n",
    "logging.warning(f\"\\n    *************************** \\n    *************************** \\n\\n\")\n",
    "#\n",
    "dfTemp = dfin2clean.copy()\n",
    "#\n",
    "dfTemp['Name'] = dfTemp['Name'].replace('MISSING', np.nan)\n",
    "dfTemp.dropna(subset=['Name'], inplace=True)\n",
    "dfName = dfTemp.groupby(['ID'])['Name'].value_counts(dropna=False).to_frame()\n",
    "del dfTemp\n",
    "dfName.columns = ['countNames']\n",
    "dfName = dfName.reset_index(level=['Name','ID'])\n",
    "dfName['IDNumeric'] = pd.to_numeric(dfName['ID'], errors='coerce', downcast='integer')\n",
    "dfName.sort_values(by=['IDNumeric', 'countNames'], ascending=True, inplace=True, na_position='first')\n",
    "dfName = dfName.drop(columns=['IDNumeric'])\n",
    "dfName.drop_duplicates(subset= ['ID'], keep='last', inplace=True)\n",
    "dfTemp = dfin2clean.copy()\n",
    "dfTemp['Name'] = dfTemp['ID'].map(dfName.set_index('ID')['Name'])\n",
    "#\n",
    "dfin2clean = dfTemp.copy()\n",
    "del dfTemp, dfName\n",
    "#\n",
    "print(f\"\\nACTION:\\nClean up of Name column.\\nFor each ID, found Name corresponding to maximum count. Then for each ID, replaced all the Name with that maximum count Name.\")\n",
    "logging.warning(f\"\\nACTION:\\nClean up of Name column.\\nFor each ID, found Name corresponding to maximum count. Then for each ID, replaced all the Name with that maximum count Name.\")\n",
    "#\n",
    "#\n",
    "#\n",
    "## ################\n",
    "## cleanup of the Sex column       ################\n",
    "#\n",
    "logging.warning(f\"\\n\\n    *************************** \\n    *************************** \")\n",
    "logging.warning(f\"\\n    *************************** \\n    *************************** \\n\\n\")\n",
    "print(f\"\\nACTION:\\nClean up of Sex column.\")\n",
    "logging.warning(f\"\\nACTION:\\nClean up of Sex column.\")\n",
    "#\n",
    "dfTemp = dfin2clean.copy()\n",
    "print(f\"\\nUnique values before cleanup=\\n{list(dfTemp['Sex'].unique())}\")\n",
    "logging.warning(f\"\\nUnique values before cleanup=\\n{list(dfTemp['Sex'].unique())}\")\n",
    "#\n",
    "dfTemp.loc[dfTemp['Sex'] == 'male', 'Sex'] = 'm'\n",
    "dfTemp.loc[dfTemp['Sex'] == 'female', 'Sex'] = 'f'\n",
    "#\n",
    "print(f\"\\nUnique values after cleanup=\\n{list(dfTemp['Sex'].unique())}\")\n",
    "logging.warning(f\"\\nUnique values after cleanup=\\n{list(dfTemp['Sex'].unique())}\")\n",
    "#\n",
    "dfin2clean = dfTemp.copy()\n",
    "del dfTemp\n",
    "#\n",
    "## additional clean up to fill missing values using cross referencing\n",
    "#\n",
    "dfTemp = dfin2clean.copy()\n",
    "#\n",
    "print(f\"\\nAdditional clean up -- using cross referencing to fill missing values.\")\n",
    "logging.warning(f\"\\nAdditional clean up -- using cross referencing to fill missing values.\")\n",
    "#\n",
    "print(f\"\\nMissing values count before cleanup=\\n{dfTemp['Sex'][dfTemp['Sex'] == 'MISSING'].count()}\")\n",
    "logging.warning(f\"\\nMissing values count before cleanup=\\n{dfTemp['Sex'][dfTemp['Sex'] == 'MISSING'].count()}\")\n",
    "#\n",
    "dfTemp['Sex'] = dfTemp['Sex'].replace('MISSING', np.nan)\n",
    "dfTemp.dropna(subset=['Sex'], inplace=True)\n",
    "dfSex = dfTemp.groupby(['ID'])['Sex'].value_counts(dropna=False).to_frame()\n",
    "del dfTemp\n",
    "dfSex.columns = ['countSex']\n",
    "dfSex = dfSex.reset_index(level=['Sex','ID'])\n",
    "dfSex['IDNumeric'] = pd.to_numeric(dfSex['ID'], errors='coerce', downcast='integer')\n",
    "dfSex.sort_values(by=['IDNumeric', 'countSex'], ascending=True, inplace=True, na_position='first')\n",
    "dfSex = dfSex.drop(columns=['IDNumeric'])\n",
    "dfSex.drop_duplicates(subset= ['ID'], keep='last', inplace=True)\n",
    "dfTemp = dfin2clean.copy()\n",
    "dfTemp['Sex'] = dfTemp['ID'].map(dfSex.set_index('ID')['Sex'])\n",
    "dfTemp['Sex'] = dfTemp['Sex'].replace(np.nan, 'MISSING')\n",
    "#\n",
    "print(f\"\\nMissing values count after cleanup=\\n{dfTemp['Sex'][dfTemp['Sex'] == 'MISSING'].count()}\")\n",
    "logging.warning(f\"\\nMissing values count after cleanup=\\n{dfTemp['Sex'][dfTemp['Sex'] == 'MISSING'].count()}\")\n",
    "#\n",
    "dfin2clean = dfTemp.copy()\n",
    "del dfTemp, dfSex\n",
    "#\n",
    "#\n",
    "#\n",
    "## ################\n",
    "## cleanup of the Age column       ################\n",
    "#\n",
    "logging.warning(f\"\\n\\n    *************************** \\n    *************************** \")\n",
    "logging.warning(f\"\\n    *************************** \\n    *************************** \\n\\n\")\n",
    "print(f\"\\nACTION:\\nClean up of Age column.\\nReplaced any values which were not numeric with the word MISSING.\")\n",
    "logging.warning(f\"\\nACTION:\\nClean up of Age column.\\nReplaced any values which were not numeric with the word MISSING.\")\n",
    "#\n",
    "dfTemp = dfin2clean.copy()\n",
    "#\n",
    "#dfTemp.loc[1255:1265]\n",
    "#\n",
    "maskValidAge = dfTemp['Age'].str.match(r'^[\\d]+$')\n",
    "maskInvalidAge = ~maskValidAge\n",
    "del(maskValidAge)\n",
    "dfTemp.loc[maskInvalidAge, 'Age'] = 'MISSING'\n",
    "del(maskInvalidAge)\n",
    "#\n",
    "#dfTemp.loc[1255:1265]\n",
    "#\n",
    "dfin2clean = dfTemp.copy()\n",
    "del dfTemp\n",
    "#\n",
    "#\n",
    "#\n",
    "## ################\n",
    "## cleanup of the Height column       ################\n",
    "#\n",
    "# one of the rows had a value of 1982.5 which is an error -- should be 182 as it matches another entry.\n",
    "# flooring all values by dropping anything after decimal.\n",
    "#\n",
    "upperLimitHeight = 250\n",
    "#\n",
    "logging.warning(f\"\\n\\n    *************************** \\n    *************************** \")\n",
    "logging.warning(f\"\\n    *************************** \\n    *************************** \\n\\n\")\n",
    "#\n",
    "print(f\"\\nACTION:\\nClean up of Height column.\\nFloored decimal values to integer values.\\nReplaced values above {upperLimitHeight} with the word MISSING.\")\n",
    "logging.warning(f\"\\nACTION:\\nClean up of Height column.\\nFloored decimal values to integer values.\\nReplaced values above {upperLimitHeight} with the word MISSING.\")\n",
    "#\n",
    "dfTemp = dfin2clean.copy()\n",
    "#\n",
    "## correcting the 1982.5 value to 182\n",
    "dfTemp.loc[dfTemp['Height'] == '1982.5', 'Height'] = '182'\n",
    "#\n",
    "## floor the values -- drop anything after the decimal\n",
    "#\n",
    "## temp code START - to check which rows already had fractional heights - using a mask to locate these rows first\n",
    "#maskFractionHeight = dfTemp['Height'].str.match(r'^[\\d]+\\.')\n",
    "#dfTemp[maskFractionHeight].head()\n",
    "## temp code END - to check which rows already had fractional heights - using a mask to locate these rows first\n",
    "#\n",
    "dfTemp['Height'] = dfTemp['Height'].replace({r'^([\\d]+)\\..*' : r'\\1'}, regex=True)\n",
    "#\n",
    "#dfTemp.loc[222779]  ## 222779 row has 1982.5 value -- which is now floored to 1982\n",
    "#\n",
    "## treating 250 as uppper limit for a valid Height value -- converting anything above that to MISSING\n",
    "#\n",
    "dfTemp['HeightAsInt'] = pd.to_numeric(dfTemp['Height'], errors='coerce', downcast='integer')\n",
    "dfTemp.loc[dfTemp['HeightAsInt'] > upperLimitHeight, 'Height'] = 'MISSING'\n",
    "print(f\"count of rows with Height above threshold that are marked as MISSING = {len(dfTemp.loc[dfTemp['HeightAsInt'] > upperLimitHeight])}\")\n",
    "#\n",
    "dfTemp = dfTemp.drop(columns=['HeightAsInt'])\n",
    "#\n",
    "dfin2clean = dfTemp.copy()\n",
    "#\n",
    "del dfTemp, upperLimitHeight\n",
    "#\n",
    "#\n",
    "#\n",
    "## ################\n",
    "## cleanup of the Weight column       ################\n",
    "#\n",
    "# six of the rows had invalid values and they were replaced by assumed valid values:\n",
    "#   MySN number            old value                     new value\n",
    "#   40990-92               7.466.666.667                 74.66\n",
    "#   246671-73              7.733.333.333                 77.33\n",
    "# flooring all values by dropping anything after decimal.\n",
    "#\n",
    "#\n",
    "logging.warning(f\"\\n\\n    *************************** \\n    *************************** \")\n",
    "logging.warning(f\"\\n    *************************** \\n    *************************** \\n\\n\")\n",
    "#\n",
    "dfTemp = dfin2clean.copy()\n",
    "#\n",
    "## replace the invalid values with valid values\n",
    "#\n",
    "## temp code START - find rows with invalid Weight values\n",
    "## below returned 6 values: MySN = 40990-92, 246671-73\n",
    "#dfTemp[dfTemp['Weight'].isin(['7.466.666.667', '7.733.333.333'])]\n",
    "#dfTemp[dfTemp['MySN'].isin(['40990', '40991', '40992', '246671', '246672', '246673'])]\n",
    "## temp code END   - find rows with invalid Weight values\n",
    "#\n",
    "dfTemp.loc[dfTemp['Weight'] == '7.466.666.667', 'Weight'] = '74.66'\n",
    "dfTemp.loc[dfTemp['Weight'] == '7.733.333.333', 'Weight'] = '77.33'\n",
    "#\n",
    "## floor the values -- drop anything after the decimal\n",
    "#\n",
    "dfTemp['Weight'] = dfTemp['Weight'].replace({r'^([\\d]+)\\..*' : r'\\1'}, regex=True)\n",
    "#\n",
    "dfin2clean = dfTemp.copy()\n",
    "del dfTemp\n",
    "#\n",
    "print(f\"\\nACTION:\\nClean up of Weight column.\\nReplaced six invalid values with valid values: MySN of 40990-92, 246671-73.\\nFloored decimal values to integer values.\")\n",
    "logging.warning(f\"\\nACTION:\\nClean up of Weight column.\\nReplaced six invalid values with valid values: MySN of 40990-92, 246671-73.\\nFloored decimal values to integer values.\")\n",
    "#\n",
    "#\n",
    "#\n",
    "## ################\n",
    "## cleanup of the Team column       ################\n",
    "#\n",
    "## clean up to fill missing values using cross referencing\n",
    "#\n",
    "logging.warning(f\"\\n\\n    *************************** \\n    *************************** \")\n",
    "logging.warning(f\"\\n    *************************** \\n    *************************** \\n\\n\")\n",
    "print(f\"\\nACTION:\\nClean up of Team column.\")\n",
    "logging.warning(f\"\\nACTION:\\nClean up of Team column.\")\n",
    "#\n",
    "dfTemp = dfin2clean.copy()\n",
    "#\n",
    "print(f\"\\nUsing cross referencing to fill missing values.\")\n",
    "logging.warning(f\"\\nUsing cross referencing to fill missing values.\")\n",
    "#\n",
    "print(f\"\\nMissing values count before cleanup=\\n{dfTemp['Team'][dfTemp['Team'] == 'MISSING'].count()}\")\n",
    "logging.warning(f\"\\nMissing values count before cleanup=\\n{dfTemp['Team'][dfTemp['Team'] == 'MISSING'].count()}\")\n",
    "#\n",
    "dfTemp['Team'] = dfTemp['Team'].replace('MISSING', np.nan)\n",
    "dfTemp.dropna(subset=['Team'], inplace=True)\n",
    "dfTeam = dfTemp.groupby(['ID'])['Team'].value_counts(dropna=False).to_frame()\n",
    "del dfTemp\n",
    "dfTeam.columns = ['countTeam']\n",
    "dfTeam = dfTeam.reset_index(level=['Team','ID'])\n",
    "dfTeam['IDNumeric'] = pd.to_numeric(dfTeam['ID'], errors='coerce', downcast='integer')\n",
    "dfTeam.sort_values(by=['IDNumeric', 'countTeam'], ascending=True, inplace=True, na_position='first')\n",
    "dfTeam = dfTeam.drop(columns=['IDNumeric'])\n",
    "dfTeam.drop_duplicates(subset= ['ID'], keep='last', inplace=True)\n",
    "dfTemp = dfin2clean.copy()\n",
    "dfTemp['Team'] = dfTemp['ID'].map(dfTeam.set_index('ID')['Team'])\n",
    "dfTemp['Team'] = dfTemp['Team'].replace(np.nan, 'MISSING')\n",
    "#\n",
    "print(f\"\\nMissing values count after cleanup=\\n{dfTemp['Team'][dfTemp['Team'] == 'MISSING'].count()}\")\n",
    "logging.warning(f\"\\nMissing values count after cleanup=\\n{dfTemp['Team'][dfTemp['Team'] == 'MISSING'].count()}\")\n",
    "#\n",
    "dfin2clean = dfTemp.copy()\n",
    "del dfTemp, dfTeam\n",
    "#\n",
    "#\n",
    "#\n",
    "## ################\n",
    "## cleanup of the NOC column       ################\n",
    "#\n",
    "## clean up to fill missing values using cross referencing\n",
    "#\n",
    "dfTemp = dfin2clean.copy()\n",
    "#\n",
    "logging.warning(f\"\\n\\n    *************************** \\n    *************************** \")\n",
    "logging.warning(f\"\\n    *************************** \\n    *************************** \\n\\n\")\n",
    "print(f\"\\nACTION:\\nClean up of NOC column.\")\n",
    "logging.warning(f\"\\nACTION:\\nClean up of NOC column.\")\n",
    "#\n",
    "print(f\"\\nUsing cross referencing to fill missing values.\")\n",
    "logging.warning(f\"\\nUsing cross referencing to fill missing values.\")\n",
    "#\n",
    "print(f\"\\nMissing values count before cleanup=\\n{dfTemp['NOC'][dfTemp['NOC'] == 'MISSING'].count()}\")\n",
    "logging.warning(f\"\\nMissing values count before cleanup=\\n{dfTemp['NOC'][dfTemp['NOC'] == 'MISSING'].count()}\")\n",
    "#\n",
    "dfTemp['NOC'] = dfTemp['NOC'].replace('MISSING', np.nan)\n",
    "dfTemp.dropna(subset=['NOC'], inplace=True)\n",
    "dfNOC = dfTemp.groupby(['ID'])['NOC'].value_counts(dropna=False).to_frame()\n",
    "del dfTemp\n",
    "dfNOC.columns = ['countNOC']\n",
    "dfNOC = dfNOC.reset_index(level=['NOC','ID'])\n",
    "dfNOC['IDNumeric'] = pd.to_numeric(dfNOC['ID'], errors='coerce', downcast='integer')\n",
    "dfNOC.sort_values(by=['IDNumeric', 'countNOC'], ascending=True, inplace=True, na_position='first')\n",
    "dfNOC = dfNOC.drop(columns=['IDNumeric'])\n",
    "dfNOC.drop_duplicates(subset= ['ID'], keep='last', inplace=True)\n",
    "dfTemp = dfin2clean.copy()\n",
    "dfTemp['NOC'] = dfTemp['ID'].map(dfNOC.set_index('ID')['NOC'])\n",
    "dfTemp['NOC'] = dfTemp['NOC'].replace(np.nan, 'MISSING')\n",
    "#\n",
    "print(f\"\\nMissing values count after cleanup=\\n{dfTemp['NOC'][dfTemp['NOC'] == 'MISSING'].count()}\")\n",
    "logging.warning(f\"\\nMissing values count after cleanup=\\n{dfTemp['NOC'][dfTemp['NOC'] == 'MISSING'].count()}\")\n",
    "#\n",
    "dfin2clean = dfTemp.copy()\n",
    "del dfTemp, dfNOC\n",
    "#\n",
    "#\n",
    "#\n",
    "## ################\n",
    "## cleanup of the Games column       ################\n",
    "#\n",
    "####  no clean up of collumns required\n",
    "logging.warning(f\"\\n\\n    *************************** \\n    *************************** \")\n",
    "logging.warning(f\"\\n    *************************** \\n    *************************** \\n\\n\")\n",
    "print(f\"\\nACTION:\\nClean up of Games column.\\nNote: No clean up required\")\n",
    "logging.warning(f\"\\nACTION:\\nClean up of Games column.\\nNote: No clean up required\")\n",
    "#\n",
    "#\n",
    "#\n",
    "## ################\n",
    "## cleanup of the Year column       ################\n",
    "#\n",
    "logging.warning(f\"\\n\\n    *************************** \\n    *************************** \")\n",
    "logging.warning(f\"\\n    *************************** \\n    *************************** \\n\\n\")\n",
    "#\n",
    "dfTemp = dfin2clean.copy()\n",
    "#\n",
    "print(f\"\\nACTION:\\nClean up of Year column.\")\n",
    "logging.warning(f\"\\nACTION:\\nClean up of Year column.\")\n",
    "#\n",
    "print(f\"\\nYear does not always match the data as per the Games column. So overwriting all values by extracting from Games column.\")\n",
    "logging.warning(f\"\\nYear does not always match the data as per the Games column. So overwriting all values by extracting from Games column.\")\n",
    "#\n",
    "## created new column, counted and logged mismatches, replaced with extracted values, deleted the new column\n",
    "dfTemp['newYear'] = dfTemp['Games'].str.extract(r'^(\\d\\d\\d\\d)', expand=True)\n",
    "#\n",
    "## log how many values were mismatched\n",
    "print(f\"\\nCount of rows with mismatch for YEAR = {len(dfTemp.loc[dfTemp['Year'] != dfTemp['newYear']])}\")\n",
    "logging.warning(f\"\\nCount of rows with mismatch for YEAR = {len(dfTemp.loc[dfTemp['Year'] != dfTemp['newYear']])}\")\n",
    "#\n",
    "dfTemp['Year'] = dfTemp['newYear']\n",
    "dfTemp = dfTemp.drop(columns=['newYear'])\n",
    "#\n",
    "dfin2clean = dfTemp.copy()\n",
    "del dfTemp\n",
    "#\n",
    "#\n",
    "#\n",
    "## ################\n",
    "## cleanup of the Season column       ################\n",
    "#\n",
    "logging.warning(f\"\\n\\n    *************************** \\n    *************************** \")\n",
    "logging.warning(f\"\\n    *************************** \\n    *************************** \\n\\n\")\n",
    "#\n",
    "dfTemp = dfin2clean.copy()\n",
    "#\n",
    "print(f\"\\nACTION:\\nClean up of Season column.\")\n",
    "logging.warning(f\"\\nACTION:\\nClean up of Season column.\")\n",
    "#\n",
    "print(f\"\\nSeason does not always match the data as per the Games column. So overwriting all values by extracting from Games column.\")\n",
    "logging.warning(f\"\\nSeason does not always match the data as per the Games column. So overwriting all values by extracting from Games column.\")\n",
    "#\n",
    "## created new column, counted and logged mismatches, replaced with extracted values, deleted the new column\n",
    "dfTemp['newSeason'] = dfTemp['Games'].str.extract(r'^\\d\\d\\d\\d (.+)$', expand=True)\n",
    "#\n",
    "print(f\"\\nCount of rows with mismatch for SEASON = {len(dfTemp.loc[dfTemp['Season'] != dfTemp['newSeason']])}\")\n",
    "logging.warning(f\"\\nCount of rows with mismatch for SEASON = {len(dfTemp.loc[dfTemp['Season'] != dfTemp['newSeason']])}\")\n",
    "#\n",
    "dfTemp['Season'] = dfTemp['newSeason']\n",
    "dfTemp = dfTemp.drop(columns=['newSeason'])\n",
    "#\n",
    "dfin2clean = dfTemp.copy()\n",
    "del dfTemp\n",
    "#\n",
    "#\n",
    "#\n",
    "## ################\n",
    "## cleanup of the City column       ################\n",
    "#\n",
    "####  no clean up of collumns required\n",
    "logging.warning(f\"\\n\\n    *************************** \\n    *************************** \")\n",
    "logging.warning(f\"\\n    *************************** \\n    *************************** \\n\\n\")\n",
    "print(f\"\\nACTION:\\nClean up of City column.\\nNote: No clean up required\")\n",
    "logging.warning(f\"\\nACTION:\\nClean up of City column.\\nNote: No clean up required\")\n",
    "#\n",
    "#\n",
    "#\n",
    "## cleanup of the Sport column       ################\n",
    "#\n",
    "logging.warning(f\"\\n\\n    *************************** \\n    *************************** \")\n",
    "logging.warning(f\"\\n    *************************** \\n    *************************** \\n\\n\")\n",
    "#\n",
    "dfTemp = dfin2clean.copy()\n",
    "#\n",
    "print(f\"\\nACTION:\\nClean up of Sport column.\")\n",
    "logging.warning(f\"\\nACTION:\\nClean up of Sport column.\")\n",
    "#\n",
    "print(f\"\\nThe Event name starts with the text of the Sport usually.\\nWhen it does not, the value is assumed to be wrong and needs to be corrected.\")\n",
    "print(f\"\\nUsing cross referencing to fill missing values and correct wrong values.\")\n",
    "logging.warning(f\"\\nThe Event name starts with the text of the Sport usually.\\nWhen it does not, the value is assumed to be wrong and needs to be corrected.\")\n",
    "logging.warning(f\"\\nUsing cross referencing to fill missing values and correct wrong values.\")\n",
    "#\n",
    "print(f\"\\nMissing values count before cleanup=\\n{dfTemp['Sport'][dfTemp['Sport'] == 'MISSING'].count()}\")\n",
    "logging.warning(f\"\\nMissing values count before cleanup=\\n{dfTemp['Sport'][dfTemp['Sport'] == 'MISSING'].count()}\")\n",
    "#\n",
    "maskDoesStartWith = dfTemp.apply(lambda x: x.Event.startswith(x.Sport), axis=1)\n",
    "maskDoesNotStartWith = ~maskDoesStartWith\n",
    "print(f\"\\nMismatch with Event name count before cleanup=\\n{len(dfTemp[['Sport', 'Event']].loc[maskDoesNotStartWith])}\")\n",
    "logging.warning(f\"\\nMismatch with Event name count before cleanup=\\n{len(dfTemp[['Sport', 'Event']].loc[maskDoesNotStartWith])}\")\n",
    "#\n",
    "dfSportEvent = dfTemp.groupby(['Event'])['Sport'].value_counts(dropna=False).to_frame()\n",
    "del dfTemp\n",
    "dfSportEvent.columns = ['countSportEvent']\n",
    "dfSportEvent = dfSportEvent.reset_index(level=['Sport','Event'])\n",
    "dfSportEvent.sort_values(by=['Event', 'countSportEvent'], ascending=True, inplace=True, na_position='first')\n",
    "dfSportEvent.drop_duplicates(subset= ['Event'], keep='last', inplace=True)\n",
    "dfTemp = dfin2clean.copy()\n",
    "dfTemp['Sport'] = dfTemp['Event'].map(dfSportEvent.set_index('Event')['Sport'])\n",
    "dfTemp['Sport'] = dfTemp['Sport'].replace(np.nan, 'MISSING')\n",
    "#\n",
    "print(f\"\\nMissing values count after cleanup=\\n{dfTemp['Sport'][dfTemp['Sport'] == 'MISSING'].count()}\")\n",
    "logging.warning(f\"\\nMissing values count after cleanup=\\n{dfTemp['Sport'][dfTemp['Sport'] == 'MISSING'].count()}\")\n",
    "#\n",
    "maskDoesStartWith = dfTemp.apply(lambda x: x.Event.startswith(x.Sport), axis=1)\n",
    "maskDoesNotStartWith = ~maskDoesStartWith\n",
    "print(f\"\\nMismatch with Event name count after cleanup=\\n{len(dfTemp[['Sport', 'Event']].loc[maskDoesNotStartWith])}\")\n",
    "logging.warning(f\"\\nMismatch with Event name count after cleanup=\\n{len(dfTemp[['Sport', 'Event']].loc[maskDoesNotStartWith])}\")\n",
    "#\n",
    "dfin2clean = dfTemp.copy()\n",
    "del dfTemp, dfSportEvent\n",
    "#\n",
    "#\n",
    "#\n",
    "## cleanup of the Event column       ################\n",
    "#\n",
    "####  no clean up of collumns required\n",
    "logging.warning(f\"\\n\\n    *************************** \\n    *************************** \")\n",
    "logging.warning(f\"\\n    *************************** \\n    *************************** \\n\\n\")\n",
    "print(f\"\\nACTION:\\nClean up of Event column.\\nNote: No clean up required\")\n",
    "logging.warning(f\"\\nACTION:\\nClean up of Event column.\\nNote: No clean up required\")\n",
    "#\n",
    "#\n",
    "#\n",
    "## ################\n",
    "## cleanup of the Medal column       ################\n",
    "#\n",
    "logging.warning(f\"\\n\\n    *************************** \\n    *************************** \")\n",
    "logging.warning(f\"\\n    *************************** \\n    *************************** \\n\\n\")\n",
    "#\n",
    "dfTemp = dfin2clean.copy()\n",
    "#\n",
    "print(f\"\\nACTION:\\nClean up of Medal column.\\nAny cell without medal replaced with 'no'.\")\n",
    "logging.warning(f\"\\nACTION:\\nClean up of Medal column.\\nAny cell without medal replaced with 'no'.\")\n",
    "#\n",
    "print(f\"\\nUnique values before cleanup=\\n{list(dfTemp['Medal'].unique())}\")\n",
    "logging.warning(f\"\\nUnique values before cleanup=\\n{list(dfTemp['Medal'].unique())}\")\n",
    "#\n",
    "dfTemp.loc[dfTemp['Medal'] == '1st', 'Medal'] = 'gold'\n",
    "dfTemp.loc[dfTemp['Medal'] == '2nd', 'Medal'] = 'silver'\n",
    "dfTemp.loc[dfTemp['Medal'] == '3rd', 'Medal'] = 'bronze'\n",
    "#\n",
    "## insert 'no' everywhere else\n",
    "#\n",
    "maskValuesWithMedal = dfTemp['Medal'].isin(['gold', 'silver', 'bronze'])\n",
    "maskValuesWithNoMedal = ~maskValuesWithMedal\n",
    "del maskValuesWithMedal\n",
    "dfTemp.loc[maskValuesWithNoMedal, 'Medal'] = 'no'\n",
    "#\n",
    "print(f\"\\nUnique values after cleanup=\\n{list(dfTemp['Medal'].unique())}\")\n",
    "logging.warning(f\"\\nUnique values after cleanup=\\n{list(dfTemp['Medal'].unique())}\")\n",
    "#\n",
    "dfin2clean = dfTemp.copy()\n",
    "del dfTemp\n",
    "#\n",
    "#\n",
    "#\n",
    "## ################\n",
    "## Final check for duplicates       ################ \n",
    "## delete row duplicates: Excluding MySN, the entire row delete if its a duplicate       ################\n",
    "#\n",
    "logging.warning(f\"\\n\\n    *************************** \\n    *************************** \")\n",
    "logging.warning(f\"\\n    *************************** \\n    *************************** \\n\\n\")\n",
    "#\n",
    "dfTemp = dfin2clean.copy()\n",
    "#\n",
    "print(f\"\\nACTION:\\nDelete duplicates, considering all coumns except MySN.\")\n",
    "(f\"\\nACTION:\\nDelete duplicates, considering all coumns except MySN.\")\n",
    "#\n",
    "print(f\"\\nNumber of rows before deduplication = {len(dfTemp)}\")\n",
    "logging.warning(f\"\\nNumber of rows before deduplication = {len(dfTemp)}\")\n",
    "#\n",
    "# create list of all columns except for MySN\n",
    "subsetCols = [col for col in list(dfTemp) if col not in ['MySN']]\n",
    "dfTemp.drop_duplicates(subset= subsetCols, keep='first', inplace=True)\n",
    "#\n",
    "print(f\"\\nNo. of rows deleted as duplicates = {dfin2clean.shape[0] -  dfTemp.shape[0]}\\n\")\n",
    "logging.warning(f\"\\nNo. of rows deleted as duplicates = {dfin2clean.shape[0] -  dfTemp.shape[0]}\\n\")\n",
    "#\n",
    "print(f\"\\nNumber of rows after deduplication = {len(dfTemp)}\")\n",
    "logging.warning(f\"\\nNumber of rows after deduplication = {len(dfTemp)}\")\n",
    "#\n",
    "## store all the MySN values for the deleted rows into the log file\n",
    "#\n",
    "setOrigSN = dfin2clean['MySN'].astype('int').copy()\n",
    "setOrigSN = set(setOrigSN.unique())\n",
    "setNoDuplicatesSN = dfTemp['MySN'].astype('int').copy()\n",
    "setNoDuplicatesSN = set(setNoDuplicatesSN.unique())\n",
    "#\n",
    "setDeletedMySNs = setOrigSN - setNoDuplicatesSN\n",
    "#\n",
    "setDeletedMySNs_asList = list(setDeletedMySNs)\n",
    "setDeletedMySNs_asList.sort()\n",
    "logging.warning(f\"\\n******* The rows with following MySN values were deleted as duplicates. *******\\n\")\n",
    "for val in setDeletedMySNs_asList:\n",
    "    logging.warning(f\"{val}\")\n",
    "logging.warning(f\"\\n******* End of deleted as duplicates information. *******\\n\")\n",
    "#\n",
    "dfin2clean = dfTemp.copy()\n",
    "#\n",
    "del dfTemp, subsetCols, setOrigSN, setNoDuplicatesSN, setDeletedMySNs_asList\n",
    "#\n",
    "#\n",
    "#\n",
    "## ################\n",
    "## CLEAN UP IS COMPLETED NOW.\n",
    "#\n",
    "logging.warning(f\"\\n\\n    *************************** \\n    *************************** \")\n",
    "logging.warning(f\"\\n    *************************** \\n    *************************** \\n\\n\")\n",
    "#\n",
    "print(f\"\\nClean up of Dataframe completed.\")\n",
    "logging.warning(f\"\\nClean up of Dataframe completed.\")\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255692, 16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfin2clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ACTION:\n",
      "Writing the output file AS IS here:\n",
      "/home/rohit/PyWDUbuntu/DM2DataCuration/Athlete_Events_CLEANDED.csv\n",
      "\n",
      "Clean data written to output file here:\n",
      "/home/rohit/PyWDUbuntu/DM2DataCuration/Athlete_Events_CLEANDED.csv\n",
      "\n",
      "Clean file statistics:\n",
      "Number of rows = 255692\n",
      "\n",
      "Number of Columns = 16\n",
      "\n",
      "Columns names are:\n",
      "['MySN', 'ID', 'Name', 'Sex', 'Age', 'Height', 'Weight', 'Team', 'NOC', 'Games', 'Year', 'Season', 'City', 'Sport', 'Event', 'Medal']\n",
      "\n",
      "Data (with MISSING replaced) written to output file here:\n",
      "/home/rohit/PyWDUbuntu/DM2DataCuration/Athlete_Events_CLEANDED_MissingReplaced.csv\n",
      "\n",
      "Clean file statistics:\n",
      "Number of rows = 255692\n",
      "\n",
      "Number of Columns = 16\n",
      "\n",
      "Columns names are:\n",
      "['MySN', 'ID', 'Name', 'Sex', 'Age', 'Height', 'Weight', 'Team', 'NOC', 'Games', 'Year', 'Season', 'City', 'Sport', 'Event', 'Medal']\n",
      "\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "## ################\n",
    "## Write the cleaned dataframe to outfile file - AS IS.\n",
    "#\n",
    "logging.warning(f\"\\n\\n    *************************** \\n    *************************** \")\n",
    "logging.warning(f\"\\n    *************************** \\n    *************************** \\n\\n\")\n",
    "#\n",
    "outFilePath = '/home/rohit/PyWDUbuntu/DM2DataCuration/'\n",
    "outCleanDataFile = 'Athlete_Events_CLEANDED.csv'\n",
    "#\n",
    "#\n",
    "print(f\"\\nACTION:\\nWriting the output file AS IS here:\\n{outFilePath + outCleanDataFile}\")\n",
    "logging.warning(f\"\\nACTION:\\nWriting the output file AS IS here:\\n{outFilePath + outCleanDataFile}\")\n",
    "#\n",
    "dfin2clean.to_csv(outFilePath + outCleanDataFile, index=False)\n",
    "#\n",
    "print(f\"\\nClean data written to output file here:\\n{outFilePath + outCleanDataFile}\")\n",
    "logging.warning(f\"\\nClean data written to output file here:\\n{outFilePath + outCleanDataFile}\")\n",
    "#\n",
    "print(f\"\\nClean file statistics:\\nNumber of rows = {len(dfin2clean)}\")\n",
    "print(f\"\\nNumber of Columns = {dfin2clean.shape[1]}\")\n",
    "logging.warning(f\"\\nClean file statistics:\\nNumber of rows = {len(dfin2clean)}\")\n",
    "logging.warning(f\"\\nNumber of Columns = {dfin2clean.shape[1]}\")\n",
    "#\n",
    "print(f\"\\nColumns names are:\\n{[colName for colName in list(dfin2clean)]}\")\n",
    "logging.warning(f\"Columns names are:\\n{[colName for colName in list(dfin2clean)]}\")\n",
    "logging.warning(f\"\\n\")\n",
    "#\n",
    "#\n",
    "#\n",
    "## ################\n",
    "## replace MISSING values with appropriate values.\n",
    "## Write this dataframe to outfile file - with replaced values.\n",
    "#\n",
    "#  column              old value                        new value\n",
    "#  MySN                NA -  no missing values\n",
    "#  ID                  NA -  no missing values\n",
    "#  Name                NA -  no missing values\n",
    "#  Sex                 NA -  no missing values\n",
    "#  Age                 MISSING                          -1\n",
    "#  Height              MISSING                          -1\n",
    "#  Weight              MISSING                          -1\n",
    "#  Team                NA -  no missing values\n",
    "#  NOC                 NA -  no missing values\n",
    "#  Games               NA -  no missing values\n",
    "#  Year                NA -  no missing values\n",
    "#  Season              NA -  no missing values\n",
    "#  City                NA -  no missing values\n",
    "#  Sport               NA -  no missing values\n",
    "#  Event               NA -  no missing values\n",
    "#  Medal               NA -  no missing values\n",
    "#################################################\n",
    "#################################################\n",
    "#\n",
    "dfin2cleanMissingReplaced = dfin2clean.copy()\n",
    "#\n",
    "dfin2cleanMissingReplaced['Age']    = dfin2cleanMissingReplaced['Age'].replace('MISSING',    '-1')\n",
    "dfin2cleanMissingReplaced['Height'] = dfin2cleanMissingReplaced['Height'].replace('MISSING', '-1')\n",
    "dfin2cleanMissingReplaced['Weight'] = dfin2cleanMissingReplaced['Weight'].replace('MISSING', '-1')\n",
    "#\n",
    "## Writing to outfile file - with MISSING values REPLACED.\n",
    "#\n",
    "logging.warning(f\"\\n\\n    *************************** \\n    *************************** \")\n",
    "logging.warning(f\"\\n    *************************** \\n    *************************** \\n\\n\")\n",
    "#\n",
    "outFilePath = '/home/rohit/PyWDUbuntu/DM2DataCuration/'\n",
    "outCleanDataFile = 'Athlete_Events_CLEANDED_MissingReplaced.csv'\n",
    "#\n",
    "dfin2cleanMissingReplaced.to_csv(outFilePath + outCleanDataFile, index=False)\n",
    "#\n",
    "print(f\"\\nData (with MISSING replaced) written to output file here:\\n{outFilePath + outCleanDataFile}\")\n",
    "logging.warning(f\"\\nData (with MISSING replaced) written to output file here:\\n{outFilePath + outCleanDataFile}\")\n",
    "#\n",
    "print(f\"\\nClean file statistics:\\nNumber of rows = {len(dfin2cleanMissingReplaced)}\")\n",
    "print(f\"\\nNumber of Columns = {dfin2cleanMissingReplaced.shape[1]}\")\n",
    "logging.warning(f\"\\nClean file statistics:\\nNumber of rows = {len(dfin2cleanMissingReplaced)}\")\n",
    "logging.warning(f\"\\nNumber of Columns = {dfin2cleanMissingReplaced.shape[1]}\")\n",
    "#\n",
    "print(f\"\\nColumns names are:\\n{[colName for colName in list(dfin2cleanMissingReplaced)]}\")\n",
    "logging.warning(f\"Columns names are:\\n{[colName for colName in list(dfin2cleanMissingReplaced)]}\")\n",
    "logging.warning(f\"\\n\")\n",
    "#\n",
    "del dfin2clean, dfin2cleanMissingReplaced\n",
    "#\n",
    "#\n",
    "#\n",
    "print(f\"\\n\\nDone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
